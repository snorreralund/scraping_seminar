{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center>Accessing data from the web</center>**\n",
    "***<center>Crawling, scraping, and APIs</center>***\n",
    "\n",
    "<center>Snorre Ralund</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Todays message **\n",
    "* Utilize the datasources around you. (Job data and crime)\n",
    "* Knowing how to create your own custom datasets pulling information from many different sources.\n",
    "* You should know all the tricks, but use them with care. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agenda**\n",
    "\n",
    "* The basics of webscraping\n",
    "    * Connecting, Crawling, Parsing, Storing, Logging.\n",
    "* Hacks: Backdoors, url construction, and analysis of a webpage.\n",
    "* Reliability of your datacollection.\n",
    "* Screen-scraping - Automated browsing\n",
    "    * Interactions:\n",
    "        * Login in, scrolling, pressing buttons.\n",
    "* APIs \n",
    "    * Authentication\n",
    "    * Building queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics / Legal Issues\n",
    "* If a regular user can’t access it, we shouldn’t try to get it (That is considered hacking)https://www.dr.dk/nyheder/penge/gjorde-opmaerksom-paa-cpr-hul-nu-bliver-han-politianmeldt-hacking. \n",
    "* Don't hit it to fast: Essentially a DENIAL OF SERVICE attack (DOS). [Again considered hacking](https://www.dr.dk/nyheder/indland/folketingets-hjemmeside-ramt-af-hacker-angreb). \n",
    "* Add headers stating your name and email with your requests to ensure transparency. \n",
    "* Be careful with copyrighted material.\n",
    "* Fair use (don't take everything)\n",
    "* If monetizing on the data, be careful not to be in direct competition with whom you are taking the data from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/snorreralund/images/raw/master/Sk%C3%A6rmbillede%202017-08-03%2014.46.32.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the essentials:\n",
    "Good practices:\n",
    "* Transparency\n",
    "* Ratelimiting\n",
    "* Reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'User-Agent': 'python-requests/2.18.4', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'email': 'youremail', 'name': 'name'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transparent scraping\n",
    "import requests\n",
    "#response = requests.get('https://www.google.com') # url, address of the site and instructions on where you wanna go.\n",
    "session = requests.session()\n",
    "session.headers['email'] = 'youremail' \n",
    "session.headers['name'] = 'name'\n",
    "session.headers # Who you are, what format you want, and authentification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick tip is that you can change the user agent to a cellphone to obtain more simple formatting of the html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Control the pace of your calls\n",
    "import time\n",
    "def ratelimit():\n",
    "    \"A function that handles the rate of your calls.\"\n",
    "    time.sleep(1)\n",
    "# Reliable requests\n",
    "def get(url,iterations=10,exceptions=(Exception)):\n",
    "    \"\"\"This module ensures that your script does not crash from connection errors.\n",
    "        iterations : Define number of iterations before giving up. \n",
    "        exceptions: Define which exceptions you accept, default is all. \n",
    "    \"\"\"\n",
    "    for iteration in range(iterations):\n",
    "        try:\n",
    "            # add ratelimit function call here\n",
    "            ratelimit() # !!\n",
    "            response = session.get(url)\n",
    "            return response # if succesful it will end the iterations here\n",
    "        except exceptions as e: #  find exceptions in the request library requests.exceptions\n",
    "            print(e) # print or log the exception message.\n",
    "    return None # your code will purposely crash if you don't create a check function later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Interactive browsing - more on this later\n",
    "from selenium import webdriver\n",
    "path2gecko = '/Users/axelengbergpallesen/Downloads/geckodriver' # define path to your geckodriver\n",
    "browser = webdriver.Firefox(executable_path=path2gecko)\n",
    "browser.get('https://www.google.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = get() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** HTML is a mess.** \n",
    "\n",
    "For now lets look at how to collect well-structured data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIS\n",
    "For fast, efficient and ***reliable*** data collection.\n",
    "\n",
    "Only catch is that they control the amounts, and which endpoints you can collect \n",
    "\n",
    "also they **change**.\n",
    "    - e.g. facebook cancelled \n",
    "        - querying friendship relations (without having users signing up to your app), \n",
    "        - group activity without admin rights, \n",
    "        - and most recently the ability to trace public activity (likes and comments) without admin rights.\n",
    "    - twitter (and more recently facebook) will not let you collect all historic activity --> streaming data.\n",
    "\n",
    "Begins with reading the docs... \n",
    "- getting authentification - creating apps, getting and renewing tokens - \n",
    "- building queries.\n",
    "- ratelimiting and pagination.\n",
    "\n",
    "Often comes in the Json format. --> nested dictionaries and lists.\n",
    "\n",
    "Example: Explore the facebook api here: https://developers.facebook.com/tools/explorer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APIS: Collect data from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# XXX: Go to http://dev.twitter.com/apps/new to create an app and get values\n",
    "# for these credentials that you'll need to provide in place of these\n",
    "# empty string values that are defined as placeholders.\n",
    "# See https://dev.twitter.com/docs/auth/oauth for more information \n",
    "# on Twitter's OAuth implementation\n",
    "\n",
    "CONSUMER_KEY=\"\"\n",
    "CONSUMER_SECRET=\"\"\n",
    "OAUTH_TOKEN=\"\"\n",
    "OAUTH_TOKEN_SECRET=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pickle.dump([CONSUMER_KEY,CONSUMER_SECRET,OAUTH_TOKEN,OAUTH_TOKEN_SECRET],open('twitter_credentials.pkl','wb'))\n",
    "CONSUMER_KEY,CONSUMER_SECRET,OAUTH_TOKEN,OAUTH_TOKEN_SECRET = pickle.load(open('twitter_credentials.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How to use this authentification?\n",
    "# answer from https://stackoverflow.com/questions/33308634/how-to-perform-oauth-when-doing-twitter-scrapping-with-python-requests\n",
    "from requests_oauthlib import OAuth1\n",
    "\n",
    "url ='https://api.twitter.com/1.1/search/tweets.json?q=bitcoin' \n",
    "auth = OAuth1(CONSUMER_KEY, CONSUMER_SECRET, OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "response = requests.get(url, auth=auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# See the ratelimits by looking at the response headers\n",
    "response.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We want to include the authentification in all calls to twitter\n",
    "session.auth = auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets inspect the response\n",
    "import pandas as pd\n",
    "status_df = pd.DataFrame(response_json['statuses']) \n",
    "#response_json['statuses'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case: Collecting data about danish politics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## searching for hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "url ='https://api.twitter.com/1.1/search/tweets.json?q=dkpol' \n",
    "#response_json['statuses'][4].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#response_json['statuses'][12]['retweeted_status']#['retweet_count']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### paging results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! mkdir  # create directory for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_path = ''\n",
    "for i in range(5): # get the next 5 results\n",
    "    next_link = response_json['search_metadata']['next_results'] # grab paging link\n",
    "    max_id = response_json['search_metadata']['max_id']\n",
    "    # make another call\n",
    "    response = get(next_link)\n",
    "    # dump the raw data\n",
    "    filename = base_path+'search_%s_%d'%(search_query,max_id)\n",
    "    f = open(filename,'w')\n",
    "    f.write(response.text)\n",
    "    f.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_id = response_json['statuses'][12]['retweeted_status']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get retweets\n",
    "url = 'https://api.twitter.com/1.1/statuses/retweets/%d.json'%tweet_id\n",
    "response = get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dump the data as network data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Monitoring danish politicians on twitter\n",
    "A twitter-user with the twitter handle *politikere* has been so kind to curate a list of danish politicians.\n",
    "\n",
    "**1)** Figure out how to construct an API call to collect who this user follows. (Look in the API reference index)\n",
    "\n",
    "**2)** Next you should construct an API call to retrieve the statuses of those politicians.\n",
    "\n",
    "**extra** \n",
    "- Make a loop to collect who each politician follows (beware of ratelimits).\n",
    "- Construct a network of politicians using the Networkx package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "nav_menu": {
    "height": "198px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
